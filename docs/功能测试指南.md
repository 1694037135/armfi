# 机械臂控制系统 - 功能测试指南

> **重要**: 所有功能都可以在 **simulation模式** 下测试，无需连接physical机械臂！

---

## 📋 测试前准备

### 1. 启动系统
```bash
cd robot-control-system
# Windows:
2-启动项目.bat

# 或手动启动:
cd ai-service
python main.py

cd ../frontend
npm run dev
```

### 2. 访问界面
- 前端: http://localhost:5173
- 后端API: http://localhost:5000

### 3. 确认系统状态
- 左上角显示 "系统在线" (绿色)
- 控制模式显示 "simulation" (灰色)

---

## ✅ 测试计划 1: 预定义动作 (5分钟，无需API)

### 功能说明
- **原理**: 关键词匹配，Fast Path 路由
- **响应速度**: <100ms
- **需要配置**: ❌ 无需任何配置

### 测试步骤

1. **打开对话面板**
   - 左侧 "DeepSeek AI Panel"

2. **测试基础动作**
   ```
   输入: 点头
   预期: 机械臂执行点头动作，3D模型同步
   
   输入: 挥手
   预期: 机械臂执行挥手动作
   
   输入: 复位
   预期: 机械臂回到初始位置
   
   输入: 跳舞
   预期: 机械臂执行舞蹈动作序列
   
   输入: 转圈
   预期: 基座旋转360度
   ```

3. **测试多轮对话记忆** ✨ **新功能**
   ```
   第1轮: 点头
   第2轮: 再来一次
   预期: 系统记住上次动作，再次点头
   
   第3轮: 挥手
   第4轮: 继续
   预期: 系统记住，再次挥手
   ```

### 验证要点
- ✅ 3D模型实时响应
- ✅ 对话框显示AI回复
- ✅ 系统日志显示 "💾 用户消息已保存到记忆"
- ✅ 多轮对话能记住上下文

---

## ✅ 测试计划 2: YOLO视觉识别 (10分钟，无需API)

### 功能说明
- **原理**: YOLO8 物体检测 + 关键词匹配
- **需要配置**: ❌ 无需API (仅检测功能)
- **需要硬件**: 电脑摄像头或手机IP摄像头

### 测试步骤

1. **打开摄像头**
   - 点击右侧 "摄像头" 按钮
   - 确认画面显示正常

2. **测试物体检测**
   ```
   准备物品: 杯子、手机、键盘等常见物体
   
   输入: 你看到什么了
   预期: 系统回复 "我看到了: 1个杯子, 1个手机"
   
   输入: 画面里有什么
   预期: 系统列出检测到的物体
   ```

3. **测试检测准确性**
   - 移动物体位置
   - 更换不同物体
   - 观察检测结果变化

### 验证要点
- ✅ YOLO能识别常见物体 (80类)
- ✅ 系统日志显示 "视觉检测结果: ..."
- ✅ 对话框显示检测结果
- ⚠️ 注意: 没有API时，回复是简单的物体列表

---

## ⚠️ 测试计划 3: 复杂NLP功能 (需要API配置)

### 功能说明
- **原理**: DeepSeek API 语义理解
- **需要配置**: ✅ 需要配置 API Key
- **响应时间**: 10-30秒

### 配置步骤

1. **编辑配置文件**
   ```bash
   # 编辑 robot-control-system/ai-service/config.json
   {
     "GEMINI_API_KEY": "你的API密钥",
     "MODEL_DECISION": "deepseek-chat",
     "MODEL_FILTER": "doubao-lite-4k",
     "LLM_BASE_URL": "https://ark.cn-beijing.volces.com/api/v3"
   }
   ```

2. **重启后端服务**
   ```bash
   # 停止当前服务 (Ctrl+C)
   # 重新启动
   python main.py
   ```

### 测试步骤

1. **测试复杂组合指令**
   ```
   输入: 先复位，然后挥手
   预期: 依次执行两个动作
   
   输入: 基座转到90度，大臂抬高30度
   预期: 同时控制多个关节
   
   输入: 移动到坐标 0.2, 0.2, 0.3
   预期: IK计算并移动到目标位置
   ```

2. **测试视觉对话** (需要API + YOLO)
   ```
   输入: 帮我拿那个杯子
   预期: 
   1. YOLO识别杯子位置
   2. LLM理解"拿"的意图
   3. 计算抓取路径
   4. 执行抓取动作
   ```

### 验证要点
- ✅ 系统能理解复杂语义
- ✅ 能执行多步骤组合动作
- ✅ 视觉和控制联动工作
- ⚠️ 响应时间较长 (10-30秒)

---

## 🔧 故障排查

### 问题1: 对话没有反应
**检查**:
- 后端是否启动 (http://localhost:5000)
- 浏览器控制台是否有错误
- 系统日志是否显示 "收到用户消息"

**解决**:
```bash
# 重启后端
cd robot-control-system/ai-service
python main.py
```

### 问题2: 预定义动作不工作
**检查**:
- 输入的指令是否准确 (点头、挥手、复位等)
- 系统日志是否显示 "⚡ [Fast Path] Work command detected"

**解决**:
- 使用准确的关键词: "点头"、"挥手"、"复位"、"跳舞"、"转圈"

### 问题3: 多轮对话不记忆
**检查**:
- 系统日志是否显示 "💾 用户消息已保存到记忆"
- 文件 `ai-service/chat_history.json` 是否存在

**解决**:
- 确认已应用最新代码修复
- 检查 `memory.py` 是否正确导入

### 问题4: YOLO检测失败
**检查**:
- 系统日志是否显示 "YOLO8模型加载完成"
- 摄像头是否正常工作

**解决**:
```bash
# 检查YOLO模型文件
ls robot-control-system/yolov8n.pt

# 测试摄像头
python -c "import cv2; cap = cv2.VideoCapture(0); print(cap.isOpened())"
```

### 问题5: API调用超时
**检查**:
- 网络连接是否正常
- API Key是否正确配置
- 代理设置是否正确

**解决**:
```json
// config.json 添加代理
{
  "HTTP_PROXY": "http://127.0.0.1:7890"
}
```

---

## 📊 功能对比表

| 功能 | 需要API | 需要physical机械臂 | 响应速度 | 测试难度 |
|------|---------|-------------------|----------|----------|
| 预定义动作 | ❌ | ❌ | <100ms | ⭐ 简单 |
| 多轮对话记忆 | ❌ | ❌ | <100ms | ⭐ 简单 |
| YOLO物体检测 | ❌ | ❌ | ~500ms | ⭐⭐ 中等 |
| 简单语音控制 | ❌ | ❌ | <100ms | ⭐ 简单 |
| 复杂NLP指令 | ✅ | ❌ | 10-30s | ⭐⭐⭐ 困难 |
| 视觉抓取 | ✅ | ❌ | 10-30s | ⭐⭐⭐ 困难 |
| 点击抓取 | ❌ | ✅ | ~1s | ⭐⭐⭐⭐ 很困难 |

---

## 🎯 演示建议

### 5分钟快速演示 (无需配置)
1. 启动系统 (1分钟)
2. 演示预定义动作: 点头、挥手、复位 (2分钟)
3. 演示多轮对话: "点头" → "再来一次" (1分钟)
4. 演示YOLO检测: 打开摄像头，识别物体 (1分钟)

### 10分钟完整演示 (需要API)
1. 快速演示 (5分钟)
2. 演示复杂指令: "先复位，然后挥手" (2分钟)
3. 演示视觉对话: "你看到什么了" (2分钟)
4. 演示IK控制: "移动到坐标 0.2, 0.2, 0.3" (1分钟)

---

## 📝 测试记录模板

```markdown
## 测试日期: 2026-01-29

### 测试环境
- 操作系统: Windows 11
- Python版本: 3.10
- Node版本: 18.x
- 控制模式: simulation

### 测试结果

#### 预定义动作
- [ ] 点头 - ✅ 通过 / ❌ 失败
- [ ] 挥手 - ✅ 通过 / ❌ 失败
- [ ] 复位 - ✅ 通过 / ❌ 失败
- [ ] 跳舞 - ✅ 通过 / ❌ 失败
- [ ] 转圈 - ✅ 通过 / ❌ 失败

#### 多轮对话记忆
- [ ] 记住上次动作 - ✅ 通过 / ❌ 失败
- [ ] 上下文理解 - ✅ 通过 / ❌ 失败

#### YOLO视觉检测
- [ ] 识别杯子 - ✅ 通过 / ❌ 失败
- [ ] 识别手机 - ✅ 通过 / ❌ 失败
- [ ] 识别键盘 - ✅ 通过 / ❌ 失败

### 问题记录
1. [问题描述]
2. [解决方案]

### 备注
[其他说明]
```

---

## 🚀 下一步

1. **完成基础测试** (测试计划1和2)
2. **记录测试结果** (使用测试记录模板)
3. **准备演示脚本** (根据演示建议)
4. **配置API** (如需测试复杂功能)
5. **准备答辩材料** (基于测试结果)

---

**最后更新**: 2026-01-29
**维护者**: AI Service Team
